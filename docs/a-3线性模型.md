# 第3章 线性模型

## 3.2 线性回归

给定数据集$D=\{(x_1,y_1),(x_2,y_2),...,(x_m,y_m)\}$，其中$x_i=(x_{i1},x_{i2},...,x_{id})$，$w=(w_1,w_2,...,w_d)$，d是示例x中的属性个数。

线性模型试图学得
$$
f(x_i)=wx_i+b，使得f(x_i)\approx y_i
$$

## 算法原理

通过【发际线】高度预测【计算机水平】
$$
f(x)=w_1x_1+b
$$
二值离散特征【颜值】（好看：1，不好看：0）
$$
f(x)=w_1x_1+w_2x_2+b
$$


有序的多值离散特征【饭量】（小：1，中：2，大：3）
$$
f(x)=w_1x_1+w_2x_2+w_3x_3+b
$$


无序的多值离散特征【肤色】（黄：[1,0,0]，黑：[0,1,0]，白：[0,0,1]）
$$
f(x)=w_1x_1+w_2x_2+w_3x_3+w_4x_4+w_5x_5+w_6x_6+b
$$

## 最小二乘估计

基于均方误差最小化对模型求解的方法称为“最小二乘法”。
$$
E(w,b)=\sum_{i=1}^m(y_i-f(x_i))^2=\sum_{i=1}^m(y_i-wx_i-b)^2
$$

## 极大似然估计

用途：估计概率分布的参数值

方法：对于离散型（连续型）随机变量$X$，假设其概率质量函数为$P(x;\theta)$（概率密度函数为$p(x;\theta)$），其中$\theta$为待估计的参数值。现有$x_1,x_2,...,x_n$是来自$X$的n个独立同分布的样本，它们的联合概率是一个关于$\theta$的函数，也称为样本的似然函数。
$$
L(\theta)=\prod_{i=1}^n P(x_i;\theta)
$$
极大似然估计的直观想法：使得观测样本出现概率最大的分布就是待求分布，也就是使得似然函数$L(\theta)$取到最大值的$\theta^\prime$即为$\theta$的估计值。

对于线性回归，可以假设其为以下模型
$$
y=wx+b+\epsilon
$$
其中$\epsilon$是不受控制的随机误差，通常假设其服从均值为0的正态分布$\epsilon \sim N(0,\sigma^2)$，所以$\epsilon$的概率密度函数为
$$
p(\epsilon)=\frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{\epsilon^2}{2\sigma^2})
$$
将$\epsilon$用$y-(wx+b)$替换可得
$$
p(y)=\frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(y-(wx+b))^2}{2\sigma^2})
$$
上式可以看作$y \sim N(wx+b,\sigma^2)$，下面便可以用极大似然估计来估计w和b的值
$$
L(w,b)=\prod_{i=1}^m p(y_i)=\prod_{i=1}^{m}\frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(y_i-(wx_i+b))^2}{2\sigma^2})
\\
ln L(w,b)=\sum_{i=1}^m ln\frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(y_i-(wx_i+b))^2}{2\sigma^2})
\\=\sum_{i=1}^m ln\frac{1}{\sqrt{2\pi}\sigma}+\sum_{i=1}^m ln exp(-\frac{(y_i-(wx_i+b))^2}{2\sigma^2})
$$


